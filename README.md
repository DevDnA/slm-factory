# slm-factory

ë„ë©”ì¸ ë¬¸ì„œë¥¼ í•™ìŠµí•˜ì—¬ íŠ¹í™”ëœ ì†Œí˜• ì–¸ì–´ëª¨ë¸(SLM)ì„ ìë™ ìƒì„±í•˜ëŠ” Teacher-Student ì§€ì‹ ì¦ë¥˜ í”„ë ˆì„ì›Œí¬

---

## ëª©ì°¨

- [1. ì†Œê°œ](#1-ì†Œê°œ)
- [2. íŒŒì´í”„ë¼ì¸ íë¦„ë„](#2-íŒŒì´í”„ë¼ì¸-íë¦„ë„)
- [3. ì£¼ìš” ê¸°ëŠ¥](#3-ì£¼ìš”-ê¸°ëŠ¥)
- [4. ê¸°ìˆ  ìŠ¤íƒ](#4-ê¸°ìˆ -ìŠ¤íƒ)
- [5. ì‹œìŠ¤í…œ ìš”êµ¬ì‚¬í•­](#5-ì‹œìŠ¤í…œ-ìš”êµ¬ì‚¬í•­)
- [6. ì„¤ì¹˜](#6-ì„¤ì¹˜)
- [7. ë¹ ë¥¸ ì‹œì‘ (wizard)](#7-ë¹ ë¥¸-ì‹œì‘-wizard)
- [8. ê³ ê¸‰: ìˆ˜ë™ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰](#8-ê³ ê¸‰-ìˆ˜ë™-íŒŒì´í”„ë¼ì¸-ì‹¤í–‰)
- [9. CLI ëª…ë ¹ì–´ ë ˆí¼ëŸ°ìŠ¤](#9-cli-ëª…ë ¹ì–´-ë ˆí¼ëŸ°ìŠ¤)
- [10. ì¶œë ¥ íŒŒì¼ êµ¬ì¡°](#10-ì¶œë ¥-íŒŒì¼-êµ¬ì¡°)
- [11. í™œìš© ì˜ˆì‹œ](#11-í™œìš©-ì˜ˆì‹œ)
- [12. íŠ¸ëŸ¬ë¸”ìŠˆíŒ…](#12-íŠ¸ëŸ¬ë¸”ìŠˆíŒ…)
- [13. í”„ë¡œì íŠ¸ êµ¬ì¡°](#13-í”„ë¡œì íŠ¸-êµ¬ì¡°)
- [14. ê´€ë ¨ ë¬¸ì„œ](#14-ê´€ë ¨-ë¬¸ì„œ)
- [15. ë¼ì´ì„ ìŠ¤](#15-ë¼ì´ì„ ìŠ¤)


---

## 1. ì†Œê°œ

**slm-factory**ëŠ” ë„ë©”ì¸ ë¬¸ì„œë¥¼ í•™ìŠµí•˜ì—¬ íŠ¹í™”ëœ ì†Œí˜• ì–¸ì–´ëª¨ë¸(SLM)ì„ ìë™ ìƒì„±í•˜ëŠ” Teacher-Student ì§€ì‹ ì¦ë¥˜ í”„ë ˆì„ì›Œí¬ì…ë‹ˆë‹¤.

### ì§€ì‹ ì¦ë¥˜(Knowledge Distillation)ë€?

ì§€ì‹ ì¦ë¥˜ëŠ” ëŒ€í˜• ì–¸ì–´ëª¨ë¸(Teacher)ì˜ ì§€ì‹ì„ ì†Œí˜• ëª¨ë¸(Student)ì—ê²Œ ì „ë‹¬í•˜ëŠ” ê¸°ìˆ ì…ë‹ˆë‹¤. slm-factoryëŠ” ì´ ê³¼ì •ì„ ë‹¤ìŒê³¼ ê°™ì´ ìë™í™”í•©ë‹ˆë‹¤:

1. **Teacher ëª¨ë¸ì˜ ì—­í• **: ë„ë©”ì¸ ë¬¸ì„œë¥¼ ì½ê³  ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ì„ ìƒì„±í•©ë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, Qwen3 8Bì™€ ê°™ì€ ëŒ€í˜• ëª¨ë¸ì´ ì •ì±… ë¬¸ì„œë¥¼ ì½ê³  "ì´ ì •ì±…ì˜ ì£¼ìš” ëª©ì ì€ ë¬´ì—‡ì¸ê°€?"ë¼ëŠ” ì§ˆë¬¸ì— ìƒì„¸í•œ ë‹µë³€ì„ ì œê³µí•©ë‹ˆë‹¤.

2. **Student ëª¨ë¸ì˜ í•™ìŠµ**: Teacherê°€ ìƒì„±í•œ ì§ˆë¬¸-ë‹µë³€ ìŒì„ í•™ìŠµ ë°ì´í„°ë¡œ í™œìš©í•˜ì—¬ ì†Œí˜• ëª¨ë¸(ì˜ˆ: Gemma 1B)ì„ íŒŒì¸íŠœë‹í•©ë‹ˆë‹¤. Student ëª¨ë¸ì€ Teacherì˜ ë‹µë³€ íŒ¨í„´ê³¼ ë„ë©”ì¸ ì§€ì‹ì„ í•™ìŠµí•˜ê²Œ ë©ë‹ˆë‹¤.

3. **ê²°ê³¼ë¬¼**: ì›ë³¸ ë¬¸ì„œì˜ ë„ë©”ì¸ ì§€ì‹ì„ ë‚´ì¬í™”í•œ ê²½ëŸ‰ ëª¨ë¸ì´ ìƒì„±ë©ë‹ˆë‹¤. ì´ ëª¨ë¸ì€ Teacherë³´ë‹¤ í›¨ì”¬ ì‘ì§€ë§Œ, íŠ¹ì • ë„ë©”ì¸ì—ì„œëŠ” ìœ ì‚¬í•œ ìˆ˜ì¤€ì˜ ì„±ëŠ¥ì„ ë°œíœ˜í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

### ì™œ ì†Œí˜• ì–¸ì–´ëª¨ë¸(SLM)ì¸ê°€?

- **ë¹„ìš© íš¨ìœ¨ì„±**: ëŒ€í˜• ëª¨ë¸ ëŒ€ë¹„ ì¶”ë¡  ë¹„ìš©ì´ 10ë°° ì´ìƒ ì €ë ´í•©ë‹ˆë‹¤
- **ì†ë„**: ì‘ë‹µ ìƒì„± ì†ë„ê°€ ë¹ ë¥´ê³  ì‹¤ì‹œê°„ ì„œë¹„ìŠ¤ì— ì í•©í•©ë‹ˆë‹¤
- **í”„ë¼ì´ë²„ì‹œ**: ë¡œì»¬ í™˜ê²½ì—ì„œ ì‹¤í–‰ ê°€ëŠ¥í•˜ì—¬ ë¯¼ê°í•œ ë„ë©”ì¸ ë°ì´í„°ë¥¼ ì™¸ë¶€ë¡œ ì „ì†¡í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤
- **ë„ë©”ì¸ íŠ¹í™”**: íŠ¹ì • ë¶„ì•¼ì— ì§‘ì¤‘í•˜ì—¬ ë²”ìš© ëª¨ë¸ë³´ë‹¤ ë†’ì€ ì •í™•ë„ë¥¼ ë‹¬ì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤

### slm-factoryì˜ ìë™í™”

slm-factoryëŠ” "ë„ë©”ì¸ ë¬¸ì„œ â†’ íŒŒì¸íŠœë‹ëœ SLM" ì „í™˜ ê³¼ì •ì„ ì™„ì „íˆ ìë™í™”í•©ë‹ˆë‹¤. ì‚¬ìš©ìëŠ” ë¬¸ì„œë¥¼ ì œê³µí•˜ê³  ì„¤ì • íŒŒì¼ì„ í¸ì§‘í•˜ëŠ” ê²ƒë§Œìœ¼ë¡œ, ë¬¸ì„œ íŒŒì‹±ë¶€í„° QA ìƒì„±, ê²€ì¦, í•™ìŠµ, ë°°í¬ê¹Œì§€ ì „ì²´ íŒŒì´í”„ë¼ì¸ì„ í•œ ë²ˆì˜ ëª…ë ¹ìœ¼ë¡œ ì‹¤í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

---

## 2. íŒŒì´í”„ë¼ì¸ íë¦„ë„

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  Documents    â”€â”€â”€â–¶    Step 1        â”€â”€â”€â–¶    Step 2        â”€â”€â”€â–¶    Step 3
  PDF/HWPX/            Parse                 Generate              Validate
  HTML/TXT             ë¬¸ì„œ íŒŒì‹±             QA ìŒ ìƒì„±            QA ê²€ì¦
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â–¼                      â–¼                      â–¼
                       ParsedDocument        QA Pairs (Alpaca)    Filtered QA Pairs

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  Step 3a       â”€â”€â”€â–¶    Step 3b       â”€â”€â”€â–¶    Step 3c
  Score                 Augment               Analyze
  í’ˆì§ˆ í‰ê°€             ë°ì´í„° ì¦ê°•           í†µê³„ ë¶„ì„
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â–¼                      â–¼                      â–¼
  Scored QA Pairs       Augmented Pairs       data_analysis.json

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  Step 4        â”€â”€â”€â–¶    Step 5        â”€â”€â”€â–¶    Step 6
  Convert               Train                 Export
  ì±„íŒ… í…œí”Œë¦¿           LoRA í•™ìŠµ             ëª¨ë¸ ë°°í¬
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â–¼                      â–¼                      â–¼
  training_data.jsonl    LoRA Adapter     Merged Model + Ollama Modelfile
```

### ë‹¨ê³„ë³„ ì…ì¶œë ¥

1. **parse**: PDF/HWPX/HTML/TXT â†’ `ParsedDocument`
2. **generate**: `ParsedDocument` + Teacher LLM â†’ QA ìŒ
3. **validate**: QA ìŒ â†’ í•„í„°ë§ëœ QA ìŒ (ê·œì¹™ + ì„ë² ë”© ê²€ì¦)
4. **score**: QA ìŒ â†’ í’ˆì§ˆ ì ìˆ˜ í‰ê°€ëœ QA ìŒ (Teacher LLM 1~5ì  í‰ê°€, threshold í•„í„°ë§)
5. **augment**: QA ìŒ â†’ ì¦ê°•ëœ QA ìŒ (Teacher LLM ì§ˆë¬¸ íŒ¨ëŸ¬í”„ë ˆì´ì¦ˆ)
6. **analyze**: QA ìŒ â†’ ë¶„ì„ ë³´ê³ ì„œ (í†µê³„ ë¶„ì„, ë°ì´í„° í’ˆì§ˆ ê²½ê³ )
7. **convert**: Alpaca JSON â†’ ì±„íŒ… í…œí”Œë¦¿ JSONL
8. **train**: ì±„íŒ… ë°ì´í„° â†’ LoRA ì–´ëŒ‘í„°
9. **export**: LoRA ì–´ëŒ‘í„° â†’ ë³‘í•© ëª¨ë¸ + Ollama Modelfile

---

## 3. ì£¼ìš” ê¸°ëŠ¥

- **ë‹¤ì¤‘ í˜•ì‹ íŒŒì‹±**: PDF, HWPX(í•œê¸€), HTML, TXT/MD, DOCX(Word) ë¬¸ì„œë¥¼ ìë™ìœ¼ë¡œ íŒŒì‹±í•˜ì—¬ í…ìŠ¤íŠ¸ì™€ í‘œë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤
- **ìœ ì—°í•œ Teacher LLM ë°±ì—”ë“œ**: Ollama(ë¡œì»¬ ì‹¤í–‰) ë˜ëŠ” OpenAI í˜¸í™˜ APIë¥¼ Teacher ëª¨ë¸ë¡œ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤
- **ê·œì¹™ ê¸°ë°˜ + ì„ë² ë”© ê¸°ë°˜ QA ê²€ì¦**: ìƒì„±ëœ QA ìŒì˜ í’ˆì§ˆì„ ìë™ìœ¼ë¡œ ê²€ì¦í•˜ê³  í•„í„°ë§í•©ë‹ˆë‹¤
- **Teacher LLM ê¸°ë°˜ í’ˆì§ˆ ì ìˆ˜ í‰ê°€**: ìƒì„±ëœ QA ìŒì„ Teacher LLMì´ 1~5ì ìœ¼ë¡œ í‰ê°€í•˜ì—¬ ì €í’ˆì§ˆ ë°ì´í„°ë¥¼ ìë™ìœ¼ë¡œ í•„í„°ë§í•©ë‹ˆë‹¤
- **ì§ˆë¬¸ íŒ¨ëŸ¬í”„ë ˆì´ì¦ˆ ë°ì´í„° ì¦ê°•**: Teacher LLMì„ í™œìš©í•˜ì—¬ ì§ˆë¬¸ì„ ë‹¤ì–‘í•œ í‘œí˜„ìœ¼ë¡œ ë³€í˜•í•˜ì—¬ í•™ìŠµ ë°ì´í„°ë¥¼ ì¦ê°•í•©ë‹ˆë‹¤
- **ìë™ ë°ì´í„° ë¶„ì„ ë³´ê³ ì„œ**: ì¹´í…Œê³ ë¦¬ ë¶„í¬, ê¸¸ì´ í†µê³„, ë°ì´í„° ë¶ˆê· í˜• ê²½ê³  ë“±ì„ í¬í•¨í•œ ë¶„ì„ ë³´ê³ ì„œë¥¼ ìë™ ìƒì„±í•©ë‹ˆë‹¤
- **ìë™ ì±„íŒ… í…œí”Œë¦¿ ë³€í™˜**: HuggingFaceì˜ ëª¨ë“  ëŒ€í™”í˜• ëª¨ë¸ì„ ì§€ì›í•˜ë©°, ê° ëª¨ë¸ì˜ ì±„íŒ… í…œí”Œë¦¿ì„ ìë™ìœ¼ë¡œ ì ìš©í•©ë‹ˆë‹¤
- **LoRA íŒŒì¸íŠœë‹ + ì¡°ê¸° ì¢…ë£Œ**: íš¨ìœ¨ì ì¸ LoRA í•™ìŠµê³¼ ì¡°ê¸° ì¢…ë£Œ ê¸°ëŠ¥ìœ¼ë¡œ ê³¼ì í•©ì„ ë°©ì§€í•©ë‹ˆë‹¤
- **ì›í´ë¦­ Ollama ë°°í¬**: í•™ìŠµëœ ëª¨ë¸ì„ Ollama Modelfileë¡œ ìë™ ë³€í™˜í•˜ì—¬ ì¦‰ì‹œ ë°°í¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤
- **DOCX(Word) íŒŒì‹± ì§€ì›**: python-docxë¥¼ ì‚¬ìš©í•˜ì—¬ Word ë¬¸ì„œì˜ í…ìŠ¤íŠ¸, í‘œ, ë©”íƒ€ë°ì´í„°ë¥¼ ìë™ ì¶”ì¶œí•©ë‹ˆë‹¤
- **ì„¤ì • ê²€ì¦ ëª…ë ¹ì–´**: `slm-factory check` ëª…ë ¹ìœ¼ë¡œ ì„¤ì • íŒŒì¼, ë¬¸ì„œ ë””ë ‰í† ë¦¬, Ollama ì—°ê²°ì„ ì‚¬ì „ ì ê²€í•©ë‹ˆë‹¤
- **íŒŒì´í”„ë¼ì¸ ì¬ê°œ**: `--resume` ì˜µì…˜ìœ¼ë¡œ ì¤‘ê°„ ì €ì¥ íŒŒì¼ì—ì„œ ì¤‘ë‹¨ëœ ë‹¨ê³„ë¶€í„° ì¬ì‹¤í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤
- **Rich ì§„í–‰ë¥  í‘œì‹œ**: QA ìƒì„±, í’ˆì§ˆ í‰ê°€, ë°ì´í„° ì¦ê°• ì‹œ ì‹¤ì‹œê°„ ì§„í–‰ ë°”ë¥¼ í‘œì‹œí•©ë‹ˆë‹¤
- **ëª¨ë“ˆ ì§ì ‘ ì‹¤í–‰**: `python -m slm_factory`ë¡œ íŒ¨í‚¤ì§€ë¥¼ ì§ì ‘ ì‹¤í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤
- **í¸ì˜ CLI ë„êµ¬**: `status`ë¡œ ì§„í–‰ ìƒíƒœ í™•ì¸, `clean`ìœ¼ë¡œ ì¤‘ê°„ íŒŒì¼ ì •ë¦¬, `convert`/`export` ë‹¨ë… ì‹¤í–‰, `--verbose`/`--quiet` ë¡œê·¸ ë ˆë²¨ ì¡°ì ˆì„ ì§€ì›í•©ë‹ˆë‹¤
- **ëŒ€í™”í˜• íŒŒì´í”„ë¼ì¸ (ê¶Œì¥)**: `wizard` ëª…ë ¹ í•˜ë‚˜ë¡œ ë¬¸ì„œ ì„ íƒë¶€í„° ëª¨ë¸ ë°°í¬ê¹Œì§€ ë‹¨ê³„ë³„ë¡œ ì•ˆë‚´í•©ë‹ˆë‹¤. ì²˜ìŒ ì‚¬ìš©ìëŠ” wizardë§Œ ì‹¤í–‰í•˜ë©´ ë©ë‹ˆë‹¤
- **ìë™ ëª¨ë¸ í‰ê°€**: í•™ìŠµëœ ëª¨ë¸ì„ BLEU/ROUGE ë©”íŠ¸ë¦­ìœ¼ë¡œ ìë™ í‰ê°€í•©ë‹ˆë‹¤
- **ëª¨ë¸ ë¹„êµ (Before/After)**: Base ëª¨ë¸ê³¼ Fine-tuned ëª¨ë¸ì˜ ë‹µë³€ì„ ë‚˜ë€íˆ ë¹„êµí•©ë‹ˆë‹¤
- **GGUF ë³€í™˜**: llama.cpp í˜¸í™˜ GGUF ì–‘ìí™” í˜•ì‹ìœ¼ë¡œ ëª¨ë¸ì„ ë³€í™˜í•©ë‹ˆë‹¤
- **ì¦ë¶„ í•™ìŠµ**: ë¬¸ì„œ ì¶”ê°€ ì‹œ ê¸°ì¡´ QAë¥¼ ìœ ì§€í•˜ë©´ì„œ ìƒˆ ë¬¸ì„œë§Œ ì²˜ë¦¬í•©ë‹ˆë‹¤
- **ë©€í‹°í„´ ëŒ€í™” ìƒì„±**: QA ìŒì„ ë©€í‹°í„´ ëŒ€í™” ë°ì´í„°ë¡œ í™•ì¥í•©ë‹ˆë‹¤
- **QA ìˆ˜ë™ ë¦¬ë·° (TUI)**: ìƒì„±ëœ QA ìŒì„ TUIì—ì„œ ìŠ¹ì¸/ê±°ë¶€/í¸ì§‘í•©ë‹ˆë‹¤
- **íŒŒì´í”„ë¼ì¸ ëŒ€ì‹œë³´ë“œ (TUI)**: íŒŒì´í”„ë¼ì¸ ì§„í–‰ ìƒíƒœë¥¼ ì‹¤ì‹œê°„ TUIë¡œ ëª¨ë‹ˆí„°ë§í•©ë‹ˆë‹¤

---

## 4. ê¸°ìˆ  ìŠ¤íƒ

| ì¹´í…Œê³ ë¦¬ | íŒ¨í‚¤ì§€ | ë²„ì „ | ì—­í•  |
|---------|--------|------|------|
| **Core** | typer | >=0.9.0 | CLI í”„ë ˆì„ì›Œí¬ |
| | pydantic | >=2.0 | ì„¤ì • ê²€ì¦ |
| | pyyaml | >=6.0 | YAML íŒŒì‹± |
| | rich | >=13.0 | í„°ë¯¸ë„ ì¶œë ¥ |
| | httpx | >=0.25.0 | HTTP í´ë¼ì´ì–¸íŠ¸ |
| **Parsing** | pymupdf | >=1.24.0 | PDF íŒŒì‹± |
| | beautifulsoup4 | >=4.12 | HTML íŒŒì‹± |
| | lxml | >=5.0 | XML íŒŒì‹± (HWPX) |
| **ML/Training** | torch | >=2.1.0 | ë”¥ëŸ¬ë‹ í”„ë ˆì„ì›Œí¬ |
| | transformers | >=4.40.0 | ëª¨ë¸ ë¡œë”© ë° í•™ìŠµ |
| | datasets | >=2.18.0 | ë°ì´í„°ì…‹ ê´€ë¦¬ |
| | peft | >=0.10.0 | LoRA ì–´ëŒ‘í„° |
| | trl | >=0.8.0 | SFTTrainer |
| | accelerate | >=0.28.0 | ë¶„ì‚° í•™ìŠµ |
| | bitsandbytes | >=0.43.0 | ì–‘ìí™” |
| **Evaluation** | evaluate | >=0.4.0 | BLEU/ROUGE ë©”íŠ¸ë¦­ |
| **TUI** | textual | >=0.40.0 | TUI í”„ë ˆì„ì›Œí¬ |
| **Optional** | pykospacing | - | í•œêµ­ì–´ ë„ì–´ì“°ê¸° êµì • |
| | sentence-transformers | >=2.6.0 | ì˜ë¯¸ì  ìœ ì‚¬ë„ ê²€ì¦ |
| | pdfplumber | >=0.11.0 | ëŒ€ì²´ PDF íŒŒì„œ |
| | python-docx | - | DOCX(Word) íŒŒì‹± |
| | pytest | >=8.0 | í…ŒìŠ¤íŠ¸ í”„ë ˆì„ì›Œí¬ |

---

## 5. ì‹œìŠ¤í…œ ìš”êµ¬ì‚¬í•­

- **Python**: 3.11 ì´ìƒ
- **GPU**: CUDA ì§€ì› GPU ê¶Œì¥ (VRAM 8GB ì´ìƒ, CPU í•™ìŠµë„ ê°€ëŠ¥í•˜ë‚˜ ë§¤ìš° ëŠë¦¼)
- **Ollama**: Teacher LLMìœ¼ë¡œ Ollamaë¥¼ ì‚¬ìš©í•˜ëŠ” ê²½ìš° ì„¤ì¹˜ í•„ìš” ([ollama.com](https://ollama.com))
- **ë””ìŠ¤í¬ ê³µê°„**: ì•½ 5GB ì´ìƒ (ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ë° í•™ìŠµ ì²´í¬í¬ì¸íŠ¸ ì €ì¥)

---

## 6. ì„¤ì¹˜

```bash
git clone https://github.com/DevDnA/slm-factory.git
cd slm-factory
pip install -e ".[all]"
slm-factory --install-completion
```

ëª¨ë“  ê¸°ëŠ¥ì´ í¬í•¨ë©ë‹ˆë‹¤: PDF/HTML/TXT/HWPX/DOCX íŒŒì‹±, í•œêµ­ì–´ ë„ì–´ì“°ê¸° êµì •, ì„ë² ë”© ê¸°ë°˜ ê²€ì¦, í…ŒìŠ¤íŠ¸ ë„êµ¬, Shell ìë™ì™„ì„±.

### Shell ìë™ì™„ì„±

Tab í‚¤ë¡œ ëª…ë ¹ì–´ì™€ ì˜µì…˜ì„ ìë™ì™„ì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:

```bash
# ìë™ì™„ì„± ì„¤ì¹˜ (bash/zsh/fish/powershell ìë™ ê°ì§€)
slm-factory --install-completion

# ì…¸ ì¬ì‹œì‘ í›„ ì ìš©ë©ë‹ˆë‹¤
# ë˜ëŠ” ì¦‰ì‹œ ì ìš©:
source ~/.bashrc   # bash
source ~/.zshrc    # zsh
```

ìë™ì™„ì„±ì´ ì‘ë™í•˜ì§€ ì•Šìœ¼ë©´:

```bash
# í˜„ì¬ ì…¸ì˜ ìë™ì™„ì„± ìŠ¤í¬ë¦½íŠ¸ í™•ì¸
slm-factory --show-completion
```

---

## 7. ë¹ ë¥¸ ì‹œì‘ (wizard)

3ë‹¨ê³„ë¡œ ì²« ë²ˆì§¸ ë„ë©”ì¸ íŠ¹í™” ëª¨ë¸ì„ ìƒì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:

```bash
# 1. í”„ë¡œì íŠ¸ ìƒì„±
slm-factory init --name my-project

# 2. í•™ìŠµí•  ë¬¸ì„œë¥¼ ë„£ê¸°
cp /path/to/your/documents/*.pdf my-project/documents/

# 3. wizard ì‹¤í–‰ â€” ì´í›„ëŠ” ì•ˆë‚´ì— ë”°ë¼ ì§„í–‰
slm-factory wizard --config my-project/project.yaml
```

wizardê°€ ë‹¤ìŒì„ ìˆœì„œëŒ€ë¡œ ì•ˆë‚´í•©ë‹ˆë‹¤:

1. ì„¤ì • íŒŒì¼ í™•ì¸
2. ë¬¸ì„œ ì„ íƒ (ì „ì²´ ë˜ëŠ” ê°œë³„)
3. ë¬¸ì„œ íŒŒì‹±
4. QA ìŒ ìƒì„± (í™•ì¸ í›„ ì§„í–‰)
5. QA ê²€ì¦
6. í’ˆì§ˆ ì ìˆ˜ í‰ê°€ (ì„ íƒ)
7. ë°ì´í„° ì¦ê°• (ì„ íƒ)
8. LoRA í•™ìŠµ (í™•ì¸ í›„ ì§„í–‰)
9. ëª¨ë¸ ë‚´ë³´ë‚´ê¸° (í™•ì¸ í›„ ì§„í–‰)
10. ë©€í‹°í„´ ëŒ€í™” ìƒì„± (ì„ íƒ)
11. GGUF ë³€í™˜ (ì„ íƒ)
12. ëª¨ë¸ í‰ê°€ (ì„ íƒ)

ê° ë‹¨ê³„ì—ì„œ ê±´ë„ˆë›°ê¸°ë¥¼ ì„ íƒí•˜ë©´, ë‚˜ì¤‘ì— ì‹¤í–‰í•  ëª…ë ¹ì–´ë¥¼ ì•Œë ¤ì¤ë‹ˆë‹¤.

> **ì‚¬ì „ ì¤€ë¹„**: wizard ì‹¤í–‰ ì „ Ollama ì„œë²„ì™€ Teacher ëª¨ë¸ì´ í•„ìš”í•©ë‹ˆë‹¤:
> ```bash
> ollama serve          # ë³„ë„ í„°ë¯¸ë„ì—ì„œ ì‹¤í–‰
> ollama pull qwen3:8b  # Teacher ëª¨ë¸ ë‹¤ìš´ë¡œë“œ
> ```

ì™„ë£Œ í›„ ìƒì„±ëœ ëª¨ë¸ì„ í…ŒìŠ¤íŠ¸í•©ë‹ˆë‹¤:

```bash
cd my-project/output/merged_model
ollama create my-project-model -f Modelfile
ollama run my-project-model
```

---

## 8. ê³ ê¸‰: ìˆ˜ë™ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰

wizard ì—†ì´ ê° ë‹¨ê³„ë¥¼ ì§ì ‘ ì œì–´í•˜ë ¤ë©´ `run` ëª…ë ¹ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.

### ì„¤ì • í¸ì§‘

`my-project/project.yaml` íŒŒì¼ì„ ì—´ì–´ í•„ìš”í•œ ì„¤ì •ì„ ìˆ˜ì •í•©ë‹ˆë‹¤:

```yaml
teacher:
  model: "qwen3:8b"              # Teacher ëª¨ë¸ ì„ íƒ
  
student:
  model: "google/gemma-3-1b-it"  # Student ëª¨ë¸ ì„ íƒ

export:
  ollama:
    model_name: "my-project-model"  # ë°°í¬í•  ëª¨ë¸ ì´ë¦„
```

### ì „ì²´ íŒŒì´í”„ë¼ì¸ í•œ ë²ˆì— ì‹¤í–‰

```bash
slm-factory run --config my-project/project.yaml
```

### ë‹¨ê³„ë³„ ì‹¤í–‰

ê°œë³„ ë‹¨ê³„ë§Œ ì‹¤í–‰í•  ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤:

```bash
slm-factory parse --config my-project/project.yaml      # ë¬¸ì„œ íŒŒì‹±ë§Œ
slm-factory generate --config my-project/project.yaml    # íŒŒì‹± + QA ìƒì„±
slm-factory validate --config my-project/project.yaml    # + ê²€ì¦
slm-factory train --config my-project/project.yaml       # í•™ìŠµ
slm-factory export --config my-project/project.yaml      # ëª¨ë¸ ë‚´ë³´ë‚´ê¸°
```

> **Tip**: `slm-factory check --config my-project/project.yaml`ìœ¼ë¡œ ì„¤ì •ê³¼ í™˜ê²½ì„ ì‚¬ì „ ì ê²€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

---

## 9. CLI ëª…ë ¹ì–´ ë ˆí¼ëŸ°ìŠ¤

### --help ì¶œë ¥ ì˜ˆì‹œ

`slm-factory --help` ì‹¤í–‰ ì‹œ ë‹¤ìŒê³¼ ê°™ì´ í‘œì‹œë©ë‹ˆë‹¤:

```
 Usage: slm-factory [OPTIONS] COMMAND [ARGS]...

 Teacher-Student Knowledge Distillation framework for domain-specific SLMs.

â•­â”€ Options â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ --verbose             -v        ë””ë²„ê·¸ ë¡œê·¸ë¥¼ í‘œì‹œí•©ë‹ˆë‹¤                     â”‚
â”‚ --quiet               -q        ê²½ê³ ì™€ ì—ëŸ¬ë§Œ í‘œì‹œí•©ë‹ˆë‹¤                     â”‚
â”‚ --install-completion            Install completion for the current shell.    â”‚
â”‚ --show-completion               Show completion for the current shell, to   â”‚
â”‚                                 copy it or customize the installation.       â”‚
â”‚ --help                          Show this message and exit.                  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
â•­â”€ ğŸš€ ì‹œì‘í•˜ê¸° â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ init       ìƒˆë¡œìš´ slm-factory í”„ë¡œì íŠ¸ë¥¼ ì´ˆê¸°í™”í•©ë‹ˆë‹¤.                       â”‚
â”‚ check      í”„ë¡œì íŠ¸ ì„¤ì •ê³¼ í™˜ê²½ì„ ì‚¬ì „ ì ê²€í•©ë‹ˆë‹¤.                           â”‚
â”‚ wizard     ëŒ€í™”í˜• íŒŒì´í”„ë¼ì¸ â€” ë‹¨ê³„ë³„ë¡œ í™•ì¸í•˜ë©° ì‹¤í–‰í•©ë‹ˆë‹¤.                 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
â•­â”€ âš™ï¸ íŒŒì´í”„ë¼ì¸ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ run        ì „ì²´ íŒŒì´í”„ë¼ì¸ì„ ì‹¤í–‰í•©ë‹ˆë‹¤ (íŒŒì‹± â†’ ìƒì„± â†’ ê²€ì¦ â†’ ë³€í™˜ â†’ í›ˆë ¨ â†’  â”‚
â”‚            ë‚´ë³´ë‚´ê¸°).                                                        â”‚
â”‚ parse      ë¬¸ì„œ íŒŒì‹± ë‹¨ê³„ë§Œ ì‹¤í–‰í•©ë‹ˆë‹¤.                                      â”‚
â”‚ generate   íŒŒì‹± + QA ìƒì„± ë‹¨ê³„ë¥¼ ì‹¤í–‰í•©ë‹ˆë‹¤.                                 â”‚
â”‚ validate   íŒŒì‹± + ìƒì„± + ê²€ì¦ ë‹¨ê³„ë¥¼ ì‹¤í–‰í•©ë‹ˆë‹¤.                             â”‚
â”‚ score      íŒŒì‹± + ìƒì„± + ê²€ì¦ + í’ˆì§ˆ ì ìˆ˜ í‰ê°€ë¥¼ ì‹¤í–‰í•©ë‹ˆë‹¤.                 â”‚
â”‚ augment    íŒŒì‹± + ìƒì„± + ê²€ì¦ + ì ìˆ˜ í‰ê°€ + ë°ì´í„° ì¦ê°•ì„ ì‹¤í–‰í•©ë‹ˆë‹¤.        â”‚
â”‚ analyze    íŒŒì‹± + ìƒì„± + ê²€ì¦ + ì ìˆ˜ í‰ê°€ + ì¦ê°• í›„ ë°ì´í„° ë¶„ì„ì„            â”‚
â”‚            ì‹¤í–‰í•©ë‹ˆë‹¤.                                                       â”‚
â”‚ train      í›ˆë ¨ ë‹¨ê³„ë¥¼ ì‹¤í–‰í•©ë‹ˆë‹¤ (ì„ íƒì ìœ¼ë¡œ ì‚¬ì „ ìƒì„±ëœ ë°ì´í„° ì‚¬ìš©).      â”‚
â”‚ convert    QA ë°ì´í„°ë¥¼ í›ˆë ¨ìš© JSONL í˜•ì‹ìœ¼ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.                     â”‚
â”‚ export     í›ˆë ¨ëœ ëª¨ë¸ì„ ë‚´ë³´ëƒ…ë‹ˆë‹¤ (LoRA ë³‘í•© + Ollama Modelfile).          â”‚
â”‚ update     ë³€ê²½ëœ ë¬¸ì„œë§Œ ì¦ë¶„ ì²˜ë¦¬í•©ë‹ˆë‹¤.                                    â”‚
â”‚ generate-dialogue  QA ìŒì—ì„œ ë©€í‹°í„´ ëŒ€í™” ë°ì´í„°ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.                â”‚
â”‚ export-gguf        ë³‘í•©ëœ ëª¨ë¸ì„ GGUF í˜•ì‹ìœ¼ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.                   â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
â•­â”€ ğŸ“Š í‰ê°€ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ eval       í•™ìŠµëœ ëª¨ë¸ì„ QA ë°ì´í„°ë¡œ í‰ê°€í•©ë‹ˆë‹¤.                             â”‚
â”‚ compare    Base ëª¨ë¸ê³¼ Fine-tuned ëª¨ë¸ì˜ ë‹µë³€ì„ ë¹„êµí•©ë‹ˆë‹¤.                  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
â•­â”€ ğŸ”§ ìœ í‹¸ë¦¬í‹° â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ status     íŒŒì´í”„ë¼ì¸ ì§„í–‰ ìƒíƒœë¥¼ í™•ì¸í•©ë‹ˆë‹¤.                                â”‚
â”‚ clean      ì¤‘ê°„ ìƒì„± íŒŒì¼ì„ ì •ë¦¬í•©ë‹ˆë‹¤.                                      â”‚
â”‚ review     QA ìŒì„ ìˆ˜ë™ìœ¼ë¡œ ë¦¬ë·°í•˜ëŠ” TUIë¥¼ ì‹¤í–‰í•©ë‹ˆë‹¤.                       â”‚
â”‚ dashboard  íŒŒì´í”„ë¼ì¸ ëª¨ë‹ˆí„°ë§ TUI ëŒ€ì‹œë³´ë“œë¥¼ ì‹¤í–‰í•©ë‹ˆë‹¤.                     â”‚
â”‚ version    slm-factory ë²„ì „ì„ í‘œì‹œí•©ë‹ˆë‹¤.                                    â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
```

---

### ëª…ë ¹ì–´ ìš”ì•½

ëª¨ë“  ëª…ë ¹ì–´ì— `--verbose` (`-v`) ë˜ëŠ” `--quiet` (`-q`) ì „ì—­ ì˜µì…˜ì„ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

| ëª…ë ¹ì–´ | ì„¤ëª… | ì£¼ìš” ì˜µì…˜ |
|--------|------|----------|
| **`wizard`** | **ëŒ€í™”í˜• íŒŒì´í”„ë¼ì¸ (ê¶Œì¥)** | `--config` |
| `init` | ìƒˆ í”„ë¡œì íŠ¸ ì´ˆê¸°í™” | `--name` (í•„ìˆ˜), `--path` |
| `run` | ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ | `--config`, `--resume` |
| `parse` | ë¬¸ì„œ íŒŒì‹±ë§Œ ì‹¤í–‰ | `--config` |
| `generate` | íŒŒì‹± + QA ìƒì„± | `--config` |
| `validate` | íŒŒì‹± + ìƒì„± + ê²€ì¦ | `--config` |
| `score` | íŒŒì‹± + ìƒì„± + ê²€ì¦ + í’ˆì§ˆ í‰ê°€ | `--config`, `--resume` |
| `augment` | íŒŒì‹± + ìƒì„± + ê²€ì¦ + í‰ê°€ + ì¦ê°• | `--config`, `--resume` |
| `analyze` | íŒŒì‹± + ìƒì„± + ê²€ì¦ + í‰ê°€ + ì¦ê°• + ë¶„ì„ | `--config`, `--resume` |
| `train` | í•™ìŠµ ë‹¨ê³„ ì‹¤í–‰ | `--config`, `--data`, `--resume` |
| `status` | íŒŒì´í”„ë¼ì¸ ì§„í–‰ ìƒíƒœ í™•ì¸ | `--config` |
| `clean` | ì¤‘ê°„ ìƒì„± íŒŒì¼ ì •ë¦¬ | `--config`, `--all` |
| `convert` | QA ë°ì´í„°ë¥¼ í›ˆë ¨ìš© JSONLë¡œ ë³€í™˜ | `--config`, `--data` |
| `export` | í›ˆë ¨ëœ ëª¨ë¸ ë‚´ë³´ë‚´ê¸° (LoRA ë³‘í•©) | `--config`, `--adapter` |
| `eval` | í•™ìŠµëœ ëª¨ë¸ í‰ê°€ (BLEU/ROUGE) | `--config`, `--model` (í•„ìˆ˜), `--data` |
| `compare` | Base vs Fine-tuned ëª¨ë¸ ë¹„êµ | `--config`, `--base-model` (í•„ìˆ˜), `--finetuned-model` (í•„ìˆ˜), `--data` |
| `export-gguf` | GGUF ì–‘ìí™” í˜•ì‹ìœ¼ë¡œ ë³€í™˜ | `--config`, `--model-dir` |
| `update` | ë³€ê²½ëœ ë¬¸ì„œë§Œ ì¦ë¶„ ì²˜ë¦¬ | `--config` |
| `generate-dialogue` | ë©€í‹°í„´ ëŒ€í™” ë°ì´í„° ìƒì„± | `--config`, `--data` |
| `review` | QA ìˆ˜ë™ ë¦¬ë·° TUI | `--config`, `--data` |
| `dashboard` | íŒŒì´í”„ë¼ì¸ ëŒ€ì‹œë³´ë“œ TUI | `--config` |
| `check` | ì„¤ì • ë° í™˜ê²½ ì‚¬ì „ ì ê²€ | `--config` |
| `version` | ë²„ì „ ì •ë³´ ì¶œë ¥ | - |

---

### `wizard` - ëŒ€í™”í˜• íŒŒì´í”„ë¼ì¸ (ê¶Œì¥)

ì „ì²´ íŒŒì´í”„ë¼ì¸ì„ ë‹¨ê³„ë³„ë¡œ ì•ˆë‚´í•˜ë©° ëŒ€í™”í˜•ìœ¼ë¡œ ì‹¤í–‰í•©ë‹ˆë‹¤. ê° ë‹¨ê³„ì—ì„œ ì‚¬ìš©ìì˜ í™•ì¸ì„ ë°›ê³ , ì„ íƒì  ë‹¨ê³„(í’ˆì§ˆ í‰ê°€, ë°ì´í„° ì¦ê°•)ëŠ” ê±´ë„ˆë›¸ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

**ì‚¬ìš©ë²•**:
```bash
slm-factory wizard [--config <ì„¤ì •íŒŒì¼ê²½ë¡œ>]
```

**ì§„í–‰ ë‹¨ê³„**:
1. ì„¤ì • íŒŒì¼ ë¡œë“œ (ìë™ íƒìƒ‰ ë˜ëŠ” ì§ì ‘ ì…ë ¥)
2. ë¬¸ì„œ ì„ íƒ (ì „ì²´ ë˜ëŠ” ê°œë³„ ì„ íƒ)
3. ë¬¸ì„œ íŒŒì‹± (ìë™ ì§„í–‰)
4. QA ìŒ ìƒì„± (í™•ì¸ í›„ ì§„í–‰)
5. QA ê²€ì¦ (ìë™ ì§„í–‰)
6. í’ˆì§ˆ ì ìˆ˜ í‰ê°€ (ì„ íƒ)
7. ë°ì´í„° ì¦ê°• (ì„ íƒ)
8. LoRA í•™ìŠµ (í™•ì¸ í›„ ì§„í–‰)
9. ëª¨ë¸ ë‚´ë³´ë‚´ê¸° (í™•ì¸ í›„ ì§„í–‰)
10. ë©€í‹°í„´ ëŒ€í™” ìƒì„± (ì„ íƒ)
11. GGUF ë³€í™˜ (ì„ íƒ)
12. ëª¨ë¸ í‰ê°€ (ì„ íƒ)

ê° ë‹¨ê³„ì—ì„œ "ê±´ë„ˆëœ€"ì„ ì„ íƒí•˜ë©´ í•´ë‹¹ ë‹¨ê³„ì˜ ê²°ê³¼ë¬¼ ê²½ë¡œì™€ ë‚˜ì¤‘ì— ì‹¤í–‰í•  ëª…ë ¹ì–´ë¥¼ ì•ˆë‚´í•©ë‹ˆë‹¤.

---

### `init` - í”„ë¡œì íŠ¸ ì´ˆê¸°í™”

ìƒˆë¡œìš´ slm-factory í”„ë¡œì íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.

**ì‚¬ìš©ë²•**:
```bash
slm-factory init --name <í”„ë¡œì íŠ¸ëª…> [--path <ë¶€ëª¨ë””ë ‰í† ë¦¬>]
```

**ì˜µì…˜**:
- `--name` (í•„ìˆ˜): ìƒì„±í•  í”„ë¡œì íŠ¸ ì´ë¦„
- `--path` (ì„ íƒ, ê¸°ë³¸ê°’: `.`): í”„ë¡œì íŠ¸ë¥¼ ìƒì„±í•  ë¶€ëª¨ ë””ë ‰í† ë¦¬

**ì˜ˆì‹œ**:
```bash
slm-factory init --name policy-assistant
```

**ì¶œë ¥**:
```
Project 'policy-assistant' created at ./policy-assistant

Project structure:
  ./policy-assistant/
  ./policy-assistant/documents/
  ./policy-assistant/output/
  ./policy-assistant/project.yaml

Next steps:
  1. Add your documents to ./policy-assistant/documents
  2. Edit ./policy-assistant/project.yaml to customize settings
  3. Run: slm-factory run --config ./policy-assistant/project.yaml
```

---

### `run` - ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰

ë¬¸ì„œ íŒŒì‹±ë¶€í„° ëª¨ë¸ ë°°í¬ê¹Œì§€ ì „ì²´ íŒŒì´í”„ë¼ì¸ì„ ìˆœì°¨ì ìœ¼ë¡œ ì‹¤í–‰í•©ë‹ˆë‹¤.

**ì‚¬ìš©ë²•**:
```bash
slm-factory run [--config <ì„¤ì •íŒŒì¼ê²½ë¡œ>]
```

**ì˜µì…˜**:
- `--config` (ì„ íƒ, ê¸°ë³¸ê°’: `project.yaml`): í”„ë¡œì íŠ¸ ì„¤ì • íŒŒì¼ ê²½ë¡œ

**ì˜ˆì‹œ**:
```bash
slm-factory run --config ./my-project/project.yaml
```

**ì‹¤í–‰ ë‹¨ê³„**:
1. ë¬¸ì„œ íŒŒì‹± (parse)
2. QA ìŒ ìƒì„± (generate)
3. QA ê²€ì¦ (validate)
4. í’ˆì§ˆ ì ìˆ˜ í‰ê°€ (score) â€” scoring.enabled ì‹œ
5. ë°ì´í„° ì¦ê°• (augment) â€” augment.enabled ì‹œ
6. ë°ì´í„° ë¶„ì„ (analyze) â€” analyzer.enabled ì‹œ
7. í•™ìŠµ ë°ì´í„° ë³€í™˜ (convert)
8. LoRA í•™ìŠµ (train)
9. ëª¨ë¸ ë³‘í•© ë° ë°°í¬ (export)

---

### `parse` - ë¬¸ì„œ íŒŒì‹±

ë¬¸ì„œ íŒŒì‹± ë‹¨ê³„ë§Œ ì‹¤í–‰í•˜ì—¬ ê²°ê³¼ë¥¼ í™•ì¸í•©ë‹ˆë‹¤.

**ì‚¬ìš©ë²•**:
```bash
slm-factory parse [--config <ì„¤ì •íŒŒì¼ê²½ë¡œ>]
```

**ì˜ˆì‹œ**:
```bash
slm-factory parse --config project.yaml
```

**ì¶œë ¥**:
```
Parsed 5 documents
```

**ìƒì„± íŒŒì¼**: `output/parsed_documents.json` (ë””ë²„ê¹… ë° ì¬ê°œìš©)

---

### `generate` - QA ìƒì„±

ë¬¸ì„œ íŒŒì‹± í›„ Teacher LLMì„ ì‚¬ìš©í•˜ì—¬ QA ìŒì„ ìƒì„±í•©ë‹ˆë‹¤.

**ì‚¬ìš©ë²•**:
```bash
slm-factory generate [--config <ì„¤ì •íŒŒì¼ê²½ë¡œ>]
```

**ì˜ˆì‹œ**:
```bash
slm-factory generate --config project.yaml
```

**ì¶œë ¥**:
```
Generated 150 QA pairs from 5 documents
```

**ìƒì„± íŒŒì¼**: `output/qa_alpaca.json` (Alpaca í˜•ì‹ QA ìŒ)

---

### `validate` - QA ê²€ì¦

íŒŒì‹±, ìƒì„± í›„ QA ìŒì„ ê²€ì¦í•˜ê³  í•„í„°ë§í•©ë‹ˆë‹¤.

**ì‚¬ìš©ë²•**:
```bash
slm-factory validate [--config <ì„¤ì •íŒŒì¼ê²½ë¡œ>]
```

**ì˜ˆì‹œ**:
```bash
slm-factory validate --config project.yaml
```

**ì¶œë ¥**:
```
Validation complete: 142 accepted, 8 rejected (out of 150 generated)
```

ê²€ì¦ ê¸°ì¤€:
- ìµœì†Œ/ìµœëŒ€ ë‹µë³€ ê¸¸ì´
- ë¹ˆ ë‹µë³€ ì œê±°
- ì¤‘ë³µ ì œê±°
- ê±°ë¶€ íŒ¨í„´ ë§¤ì¹­ (ì˜ˆ: "I don't know")
- ì„ íƒì  ì˜ë¯¸ì  groundedness ì²´í¬

---

### `score` - í’ˆì§ˆ ì ìˆ˜ í‰ê°€

ë¬¸ì„œ íŒŒì‹±, QA ìƒì„±, ê²€ì¦ í›„ Teacher LLMì„ ì‚¬ìš©í•˜ì—¬ QA ìŒì˜ í’ˆì§ˆì„ 1~5ì ìœ¼ë¡œ í‰ê°€í•©ë‹ˆë‹¤.

**ì‚¬ìš©ë²•**:
```bash
slm-factory score [--config <ì„¤ì •íŒŒì¼ê²½ë¡œ>]
```

**ì˜ˆì‹œ**:
```bash
slm-factory score --config project.yaml
```

**ì¶œë ¥**:
```
Score complete: 120 passed, 22 filtered (out of 142 validated)
```

Note: scoring.enabledê°€ false(ê¸°ë³¸ê°’)ì´ë©´ ì ìˆ˜ í‰ê°€ë¥¼ ê±´ë„ˆëœë‹ˆë‹¤. project.yamlì—ì„œ scoring.enabled: trueë¡œ ì„¤ì •í•˜ì‹­ì‹œì˜¤.

---

### `augment` - ë°ì´í„° ì¦ê°•

ì ìˆ˜ í‰ê°€ê¹Œì§€ ì™„ë£Œëœ QA ìŒì„ Teacher LLMìœ¼ë¡œ ì§ˆë¬¸ íŒ¨ëŸ¬í”„ë ˆì´ì¦ˆí•˜ì—¬ ì¦ê°•í•©ë‹ˆë‹¤.

**ì‚¬ìš©ë²•**:
```bash
slm-factory augment [--config <ì„¤ì •íŒŒì¼ê²½ë¡œ>]
```

**ì˜ˆì‹œ**:
```bash
slm-factory augment --config project.yaml
```

**ì¶œë ¥**:
```
Augmentation complete: 120 â†’ 360 (240 augmented pairs added)
```

Note: augment.enabledê°€ false(ê¸°ë³¸ê°’)ì´ë©´ ì¦ê°•ì„ ê±´ë„ˆëœë‹ˆë‹¤.

---

### `analyze` - ë°ì´í„° ë¶„ì„

ì „ì²´ ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ í›„ ë°ì´í„° í†µê³„ ë¶„ì„ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.

**ì‚¬ìš©ë²•**:
```bash
slm-factory analyze [--config <ì„¤ì •íŒŒì¼ê²½ë¡œ>]
```

**ì˜ˆì‹œ**:
```bash
slm-factory analyze --config project.yaml
```

**ì¶œë ¥**: ë¶„ì„ ìš”ì•½ í…Œì´ë¸” (Rich ì½˜ì†”) + data_analysis.json ë³´ê³ ì„œ

---

### `train` - í•™ìŠµ

LoRA íŒŒì¸íŠœë‹ì„ ì‹¤í–‰í•©ë‹ˆë‹¤. ê¸°ì¡´ í•™ìŠµ ë°ì´í„°ë¥¼ ì‚¬ìš©í•˜ê±°ë‚˜ ì „ì²´ íŒŒì´í”„ë¼ì¸ì„ ì‹¤í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

**ì‚¬ìš©ë²•**:
```bash
slm-factory train [--config <ì„¤ì •íŒŒì¼ê²½ë¡œ>] [--data <í•™ìŠµë°ì´í„°ê²½ë¡œ>]
```

**ì˜µì…˜**:
- `--config` (ì„ íƒ, ê¸°ë³¸ê°’: `project.yaml`): í”„ë¡œì íŠ¸ ì„¤ì • íŒŒì¼
- `--data` (ì„ íƒ): ê¸°ì¡´ `training_data.jsonl` íŒŒì¼ ê²½ë¡œ. ì§€ì •í•˜ì§€ ì•Šìœ¼ë©´ ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰

**ì˜ˆì‹œ 1**: ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ í›„ í•™ìŠµ
```bash
slm-factory train --config project.yaml
```

**ì˜ˆì‹œ 2**: ê¸°ì¡´ í•™ìŠµ ë°ì´í„°ë¡œ í•™ìŠµë§Œ ì‹¤í–‰
```bash
slm-factory train --config project.yaml --data ./custom_qa_data.jsonl
```

**ì¶œë ¥**:
```
Training complete! Adapter saved to: ./output/checkpoints/adapter
```

---

### `status` - ì§„í–‰ ìƒíƒœ í™•ì¸

íŒŒì´í”„ë¼ì¸ì˜ ì§„í–‰ ìƒíƒœë¥¼ í™•ì¸í•©ë‹ˆë‹¤. ê° ë‹¨ê³„ì˜ ì¤‘ê°„ íŒŒì¼ ì¡´ì¬ ì—¬ë¶€ì™€ ê±´ìˆ˜ë¥¼ í‘œì‹œí•©ë‹ˆë‹¤.

**ì‚¬ìš©ë²•**: `slm-factory status [--config <ì„¤ì •íŒŒì¼ê²½ë¡œ>]`

**ì¶œë ¥ ì˜ˆì‹œ**:
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  ë‹¨ê³„       íŒŒì¼                    ìƒíƒœ   ê±´ìˆ˜
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
  parse      parsed_documents.json   ì¡´ì¬   5ê°œ ë¬¸ì„œ
  generate   qa_alpaca.json          ì¡´ì¬   150ê°œ ìŒ
  score      qa_scored.json          ì—†ìŒ   -
  ...        ...                     ...    ...
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
  ë‹¤ìŒ --resume ì‹¤í–‰ ì‹œ validateë¶€í„° ì¬ê°œë©ë‹ˆë‹¤
```

---

### `clean` - íŒŒì¼ ì •ë¦¬

ì¤‘ê°„ ìƒì„± íŒŒì¼ì„ ì •ë¦¬í•©ë‹ˆë‹¤.

**ì‚¬ìš©ë²•**: `slm-factory clean [--config <ì„¤ì •íŒŒì¼ê²½ë¡œ>] [--all]`

**ì˜µì…˜**:
- `--all`: ëª¨ë“  ì¶œë ¥ íŒŒì¼ ì‚­ì œ (ê¸°ë³¸: ì¤‘ê°„ íŒŒì¼ë§Œ â€” qa_scored.json, qa_augmented.json, data_analysis.json)

ì‚­ì œ ì „ í™•ì¸ í”„ë¡¬í”„íŠ¸ê°€ í‘œì‹œë©ë‹ˆë‹¤.

---

### `convert` - ë°ì´í„° ë³€í™˜

QA ë°ì´í„°ë¥¼ í›ˆë ¨ìš© JSONL í˜•ì‹ìœ¼ë¡œ ë³€í™˜í•©ë‹ˆë‹¤. íŒŒì´í”„ë¼ì¸ ì „ì²´ë¥¼ ì¬ì‹¤í–‰í•˜ì§€ ì•Šê³  ë³€í™˜ë§Œ ìˆ˜í–‰í•©ë‹ˆë‹¤.

**ì‚¬ìš©ë²•**: `slm-factory convert [--config <ì„¤ì •íŒŒì¼ê²½ë¡œ>] [--data <QAë°ì´í„°ê²½ë¡œ>]`

**ì˜µì…˜**:
- `--data`: QA ë°ì´í„° íŒŒì¼ ê²½ë¡œ (ë¯¸ì§€ì • ì‹œ outputì—ì„œ ìë™ ê°ì§€: qa_augmented.json â†’ qa_scored.json â†’ qa_alpaca.json)

---

### `export` - ëª¨ë¸ ë‚´ë³´ë‚´ê¸°

í›ˆë ¨ëœ ëª¨ë¸ì„ ë‚´ë³´ëƒ…ë‹ˆë‹¤ (LoRA ë³‘í•© + Ollama Modelfile). íŒŒì´í”„ë¼ì¸ ì „ì²´ë¥¼ ì¬ì‹¤í–‰í•˜ì§€ ì•Šê³  ë‚´ë³´ë‚´ê¸°ë§Œ ìˆ˜í–‰í•©ë‹ˆë‹¤.

**ì‚¬ìš©ë²•**: `slm-factory export [--config <ì„¤ì •íŒŒì¼ê²½ë¡œ>] [--adapter <ì–´ëŒ‘í„°ê²½ë¡œ>]`

**ì˜µì…˜**:
- `--adapter`: ì–´ëŒ‘í„° ë””ë ‰í† ë¦¬ ê²½ë¡œ (ë¯¸ì§€ì • ì‹œ output/checkpoints/adapter/ ì‚¬ìš©)

---

### `check` - ì„¤ì • ê²€ì¦

í”„ë¡œì íŠ¸ ì„¤ì •ê³¼ ì‹¤í–‰ í™˜ê²½ì„ ì‚¬ì „ ì ê²€í•©ë‹ˆë‹¤.

**ì‚¬ìš©ë²•**: `slm-factory check --config project.yaml`

ì ê²€ í•­ëª©:
- ì„¤ì • íŒŒì¼ ë¡œë“œ ë° Pydantic ê²€ì¦
- ë¬¸ì„œ ë””ë ‰í† ë¦¬ ì¡´ì¬ ë° íŒŒì¼ ìœ ë¬´
- ì¶œë ¥ ë””ë ‰í† ë¦¬ ì“°ê¸° ê¶Œí•œ
- Ollama ì„œë²„ ì—°ê²° (backend=ollamaì¼ ë•Œ)
- Teacher ëª¨ë¸ ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€

ëª¨ë“  í•­ëª© í†µê³¼ ì‹œ "ëª¨ë“  ì ê²€ í†µê³¼!" ë©”ì‹œì§€ì™€ í•¨ê»˜ ì¢…ë£Œ ì½”ë“œ 0ì„ ë°˜í™˜í•©ë‹ˆë‹¤.

---

### `eval` - ëª¨ë¸ í‰ê°€

í•™ìŠµëœ ëª¨ë¸ì„ BLEU/ROUGE ë©”íŠ¸ë¦­ìœ¼ë¡œ í‰ê°€í•©ë‹ˆë‹¤.

**ì‚¬ìš©ë²•**:
```bash
slm-factory eval --model <ëª¨ë¸ì´ë¦„> [--config <ì„¤ì •íŒŒì¼>] [--data <QAë°ì´í„°>]
```

**ì˜µì…˜**:
- `--model` (í•„ìˆ˜): í‰ê°€í•  Ollama ëª¨ë¸ ì´ë¦„
- `--config` (ì„ íƒ, ê¸°ë³¸ê°’: `project.yaml`): í”„ë¡œì íŠ¸ ì„¤ì • íŒŒì¼
- `--data` (ì„ íƒ): QA ë°ì´í„° íŒŒì¼ ê²½ë¡œ (ë¯¸ì§€ì • ì‹œ ìë™ ê°ì§€)

**ì˜ˆì‹œ**:
```bash
slm-factory eval --model my-project-model --config project.yaml
```

**ì¶œë ¥**: `output/evaluation_results.json` (BLEU/ROUGE ì ìˆ˜)

---

### `compare` - ëª¨ë¸ ë¹„êµ

Base ëª¨ë¸ê³¼ Fine-tuned ëª¨ë¸ì˜ ë‹µë³€ì„ ë‚˜ë€íˆ ë¹„êµí•©ë‹ˆë‹¤.

**ì‚¬ìš©ë²•**:
```bash
slm-factory compare --base-model <ê¸°ì¤€ëª¨ë¸> --finetuned-model <íŒŒì¸íŠœë‹ëª¨ë¸> [--config <ì„¤ì •íŒŒì¼>] [--data <QAë°ì´í„°>]
```

**ì˜µì…˜**:
- `--base-model` (í•„ìˆ˜): ë¹„êµ ê¸°ì¤€ ëª¨ë¸ (Ollama)
- `--finetuned-model` (í•„ìˆ˜): íŒŒì¸íŠœë‹ëœ ëª¨ë¸ (Ollama)
- `--config` (ì„ íƒ, ê¸°ë³¸ê°’: `project.yaml`): í”„ë¡œì íŠ¸ ì„¤ì • íŒŒì¼
- `--data` (ì„ íƒ): QA ë°ì´í„° íŒŒì¼ ê²½ë¡œ

**ì˜ˆì‹œ**:
```bash
slm-factory compare --base-model gemma:2b --finetuned-model my-project-model --config project.yaml
```

**ì¶œë ¥**: `output/compare_results.json` (ë‚˜ë€íˆ ë¹„êµ ê²°ê³¼)

---

### `export-gguf` - GGUF ë³€í™˜

ë³‘í•©ëœ ëª¨ë¸ì„ llama.cpp í˜¸í™˜ GGUF ì–‘ìí™” í˜•ì‹ìœ¼ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.

**ì‚¬ìš©ë²•**:
```bash
slm-factory export-gguf [--config <ì„¤ì •íŒŒì¼>] [--model-dir <ëª¨ë¸ê²½ë¡œ>]
```

**ì˜µì…˜**:
- `--config` (ì„ íƒ, ê¸°ë³¸ê°’: `project.yaml`): í”„ë¡œì íŠ¸ ì„¤ì • íŒŒì¼
- `--model-dir` (ì„ íƒ, ê¸°ë³¸ê°’: `output/merged_model`): ë³‘í•©ëœ ëª¨ë¸ ë””ë ‰í† ë¦¬

**ì˜ˆì‹œ**:
```bash
slm-factory export-gguf --config project.yaml
```

llama.cppì˜ convert ìŠ¤í¬ë¦½íŠ¸ë¥¼ ì‚¬ìš©í•˜ì—¬ GGUF ì–‘ìí™” í˜•ì‹ìœ¼ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.

---

### `update` - ì¦ë¶„ ì—…ë°ì´íŠ¸

ë³€ê²½ëœ ë¬¸ì„œë§Œ ê°ì§€í•˜ì—¬ ìƒˆ QAë¥¼ ìƒì„±í•˜ê³  ê¸°ì¡´ QAì™€ ë³‘í•©í•©ë‹ˆë‹¤.

**ì‚¬ìš©ë²•**:
```bash
slm-factory update [--config <ì„¤ì •íŒŒì¼>]
```

**ì˜µì…˜**:
- `--config` (ì„ íƒ, ê¸°ë³¸ê°’: `project.yaml`): í”„ë¡œì íŠ¸ ì„¤ì • íŒŒì¼

**ì˜ˆì‹œ**:
```bash
slm-factory update --config project.yaml
```

í•´ì‹œ ê¸°ë°˜ìœ¼ë¡œ ë³€ê²½ ê°ì§€í•˜ì—¬ ê¸°ì¡´ QAë¥¼ ìœ ì§€í•˜ë©´ì„œ ìƒˆ ë¬¸ì„œë§Œ ì²˜ë¦¬í•©ë‹ˆë‹¤.

---

### `generate-dialogue` - ëŒ€í™” ìƒì„±

QA ìŒì„ ë©€í‹°í„´ ëŒ€í™” í˜•ì‹ìœ¼ë¡œ í™•ì¥í•©ë‹ˆë‹¤.

**ì‚¬ìš©ë²•**:
```bash
slm-factory generate-dialogue [--config <ì„¤ì •íŒŒì¼>] [--data <QAë°ì´í„°>]
```

**ì˜µì…˜**:
- `--config` (ì„ íƒ, ê¸°ë³¸ê°’: `project.yaml`): í”„ë¡œì íŠ¸ ì„¤ì • íŒŒì¼
- `--data` (ì„ íƒ): QA ë°ì´í„° íŒŒì¼ ê²½ë¡œ

**ì˜ˆì‹œ**:
```bash
slm-factory generate-dialogue --config project.yaml
```

**ì¶œë ¥**: `output/dialogues.json` (ë©€í‹°í„´ ëŒ€í™” ë°ì´í„°)

---

### `review` - QA ë¦¬ë·°

TUIì—ì„œ QA ìŒì„ í•˜ë‚˜ì”© í™•ì¸í•˜ë©° ìŠ¹ì¸/ê±°ë¶€/í¸ì§‘í•©ë‹ˆë‹¤.

**ì‚¬ìš©ë²•**:
```bash
slm-factory review [--config <ì„¤ì •íŒŒì¼>] [--data <QAë°ì´í„°>]
```

**ì˜µì…˜**:
- `--config` (ì„ íƒ, ê¸°ë³¸ê°’: `project.yaml`): í”„ë¡œì íŠ¸ ì„¤ì • íŒŒì¼
- `--data` (ì„ íƒ): QA ë°ì´í„° íŒŒì¼ ê²½ë¡œ

**ì˜ˆì‹œ**:
```bash
slm-factory review --config project.yaml
```

**ì¶œë ¥**: `output/qa_reviewed.json` (ìˆ˜ë™ ë¦¬ë·°ëœ QA ìŒ)

---

### `dashboard` - ëŒ€ì‹œë³´ë“œ

íŒŒì´í”„ë¼ì¸ ì§„í–‰ ìƒíƒœë¥¼ ì‹¤ì‹œê°„ TUIë¡œ ëª¨ë‹ˆí„°ë§í•©ë‹ˆë‹¤.

**ì‚¬ìš©ë²•**:
```bash
slm-factory dashboard [--config <ì„¤ì •íŒŒì¼>]
```

**ì˜µì…˜**:
- `--config` (ì„ íƒ, ê¸°ë³¸ê°’: `project.yaml`): í”„ë¡œì íŠ¸ ì„¤ì • íŒŒì¼

**ì˜ˆì‹œ**:
```bash
slm-factory dashboard --config project.yaml
```

ê° ë‹¨ê³„ì˜ íŒŒì¼ ì¡´ì¬ ì—¬ë¶€, ê±´ìˆ˜, ìµœê·¼ ìˆ˜ì • ì‹œê°ì„ í‘œì‹œí•©ë‹ˆë‹¤.

---

### `version` - ë²„ì „ ì •ë³´

slm-factoryì˜ í˜„ì¬ ë²„ì „ì„ ì¶œë ¥í•©ë‹ˆë‹¤.

**ì‚¬ìš©ë²•**:
```bash
slm-factory version
```

**ì¶œë ¥**:
```
slm-factory 0.1.0
```

---

## 10. ì¶œë ¥ íŒŒì¼ êµ¬ì¡°

íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ í›„ `output/` ë””ë ‰í† ë¦¬ì— ë‹¤ìŒ íŒŒì¼ë“¤ì´ ìƒì„±ë©ë‹ˆë‹¤:

```
output/
â”œâ”€â”€ parsed_documents.json       # íŒŒì‹±ëœ ë¬¸ì„œ (ë””ë²„ê¹… ë° ì¬ê°œìš©)
â”œâ”€â”€ qa_alpaca.json             # ìƒì„±ëœ QA ìŒ (Alpaca í˜•ì‹)
â”œâ”€â”€ qa_scored.json             # ì ìˆ˜ í‰ê°€ëœ QA ìŒ (ì¬ê°œìš©)
â”œâ”€â”€ qa_augmented.json          # ì¦ê°•ëœ QA ìŒ (ì¬ê°œìš©)
â”œâ”€â”€ qa_reviewed.json           # ìˆ˜ë™ ë¦¬ë·°ëœ QA ìŒ
â”œâ”€â”€ data_analysis.json         # ë°ì´í„° ë¶„ì„ ë³´ê³ ì„œ
â”œâ”€â”€ dialogues.json             # ë©€í‹°í„´ ëŒ€í™” ë°ì´í„°
â”œâ”€â”€ evaluation_results.json    # ëª¨ë¸ í‰ê°€ ê²°ê³¼ (BLEU/ROUGE)
â”œâ”€â”€ compare_results.json       # ëª¨ë¸ ë¹„êµ ê²°ê³¼ (Before/After)
â”œâ”€â”€ training_data.jsonl        # ì±„íŒ… í…œí”Œë¦¿ ì ìš©ëœ í•™ìŠµ ë°ì´í„°
â”œâ”€â”€ checkpoints/
â”‚   â””â”€â”€ adapter/               # LoRA ì–´ëŒ‘í„° ê°€ì¤‘ì¹˜
â”‚       â”œâ”€â”€ adapter_config.json
â”‚       â”œâ”€â”€ adapter_model.safetensors
â”‚       â””â”€â”€ ...
â””â”€â”€ merged_model/              # ë³‘í•©ëœ ìµœì¢… ëª¨ë¸
    â”œâ”€â”€ config.json
    â”œâ”€â”€ model.safetensors
    â”œâ”€â”€ tokenizer.json
    â”œâ”€â”€ tokenizer_config.json
    â””â”€â”€ Modelfile              # Ollama ë°°í¬ íŒŒì¼
```

### íŒŒì¼ ì„¤ëª…

- **`parsed_documents.json`**: ì›ë³¸ ë¬¸ì„œì—ì„œ ì¶”ì¶œí•œ í…ìŠ¤íŠ¸, í‘œ, ë©”íƒ€ë°ì´í„°ë¥¼ JSON í˜•ì‹ìœ¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤. íŒŒì´í”„ë¼ì¸ ì¬ê°œ ì‹œ íŒŒì‹± ë‹¨ê³„ë¥¼ ê±´ë„ˆë›¸ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

- **`qa_alpaca.json`**: Teacher LLMì´ ìƒì„±í•œ ì§ˆë¬¸-ë‹µë³€ ìŒì„ Alpaca í˜•ì‹ìœ¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤. ê° í•­ëª©ì€ `instruction`, `input`, `output` í•„ë“œë¥¼ í¬í•¨í•©ë‹ˆë‹¤.

- **`qa_scored.json`**: í’ˆì§ˆ ì ìˆ˜ í‰ê°€ë¥¼ í†µê³¼í•œ QA ìŒì…ë‹ˆë‹¤. `--resume` ì˜µì…˜ìœ¼ë¡œ augment ë‹¨ê³„ë¶€í„° ì¬ê°œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

- **`qa_augmented.json`**: ë°ì´í„° ì¦ê°•ì´ ì™„ë£Œëœ QA ìŒì…ë‹ˆë‹¤. `--resume` ì˜µì…˜ìœ¼ë¡œ analyze ë‹¨ê³„ë¶€í„° ì¬ê°œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

- **`qa_reviewed.json`**: TUIì—ì„œ ìˆ˜ë™ ë¦¬ë·°ë¥¼ ê±°ì¹œ QA ìŒì…ë‹ˆë‹¤. ìŠ¹ì¸ëœ QAë§Œ í¬í•¨ë˜ë©°, í¸ì§‘ëœ ë‚´ìš©ì´ ë°˜ì˜ë©ë‹ˆë‹¤.

- **`data_analysis.json`**: QA ë°ì´í„°ì˜ í†µê³„ ë¶„ì„ ë³´ê³ ì„œì…ë‹ˆë‹¤. ì¹´í…Œê³ ë¦¬ ë¶„í¬, ë¬¸ì„œë³„ ë¶„í¬, ë‹µë³€/ì§ˆë¬¸ ê¸¸ì´ í†µê³„, ë°ì´í„° í’ˆì§ˆ ê²½ê³ ë¥¼ í¬í•¨í•©ë‹ˆë‹¤.

- **`dialogues.json`**: QA ìŒì„ ë©€í‹°í„´ ëŒ€í™” í˜•ì‹ìœ¼ë¡œ í™•ì¥í•œ ë°ì´í„°ì…ë‹ˆë‹¤. ëŒ€í™”í˜• ëª¨ë¸ í•™ìŠµì— í™œìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

- **`evaluation_results.json`**: í•™ìŠµëœ ëª¨ë¸ì˜ BLEU/ROUGE ì ìˆ˜ í‰ê°€ ê²°ê³¼ì…ë‹ˆë‹¤. ê° ë©”íŠ¸ë¦­ë³„ ì ìˆ˜ì™€ í‰ê·  ì ìˆ˜ë¥¼ í¬í•¨í•©ë‹ˆë‹¤.

- **`compare_results.json`**: Base ëª¨ë¸ê³¼ Fine-tuned ëª¨ë¸ì˜ ë‹µë³€ì„ ë‚˜ë€íˆ ë¹„êµí•œ ê²°ê³¼ì…ë‹ˆë‹¤. ê° ì§ˆë¬¸ì— ëŒ€í•œ ë‘ ëª¨ë¸ì˜ ë‹µë³€ì„ í¬í•¨í•©ë‹ˆë‹¤.

- **`training_data.jsonl`**: Student ëª¨ë¸ì˜ ì±„íŒ… í…œí”Œë¦¿ì´ ì ìš©ëœ í•™ìŠµ ë°ì´í„°ì…ë‹ˆë‹¤. ê° ì¤„ì€ `{"text": "..."}` í˜•ì‹ì˜ JSON ê°ì²´ì´ë©°, `text` í•„ë“œì— ì±„íŒ… í…œí”Œë¦¿ì´ ì ìš©ëœ ì „ì²´ ëŒ€í™” ë¬¸ìì—´ì´ í¬í•¨ë©ë‹ˆë‹¤.

- **`checkpoints/adapter/`**: LoRA í•™ìŠµ ì¤‘ ì €ì¥ëœ ì–´ëŒ‘í„° ê°€ì¤‘ì¹˜ì…ë‹ˆë‹¤. PEFT í˜•ì‹ìœ¼ë¡œ ì €ì¥ë˜ë©°, ì›ë³¸ ëª¨ë¸ê³¼ ê²°í•©í•˜ì—¬ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

- **`merged_model/`**: LoRA ì–´ëŒ‘í„°ê°€ ì›ë³¸ Student ëª¨ë¸ê³¼ ë³‘í•©ëœ ìµœì¢… ëª¨ë¸ì…ë‹ˆë‹¤. HuggingFace í˜•ì‹ìœ¼ë¡œ ì €ì¥ë˜ë©°, `Modelfile`ì„ í†µí•´ Ollamaì— ì¦‰ì‹œ ë°°í¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

---

## 11. í™œìš© ì˜ˆì‹œ

### ì˜ˆì‹œ 1: í•œêµ­ì–´ ì •ì±… ë¬¸ì„œ(HWPX) â†’ ì •ì±… ì „ë¬¸ ëª¨ë¸

í•œêµ­ ì •ë¶€ ì •ì±… ë¬¸ì„œ(HWPX í˜•ì‹)ë¥¼ í•™ìŠµí•˜ì—¬ ì •ì±… ì§ˆì˜ì‘ë‹µ ëª¨ë¸ì„ ìƒì„±í•©ë‹ˆë‹¤.

**ì„¤ì • íŒŒì¼** (`policy-project/project.yaml`):
```yaml
project:
  name: "policy-assistant"
  language: "ko"

paths:
  documents: "./documents"
  output: "./output"

parsing:
  formats: ["hwpx"]
  hwpx:
    apply_spacing: true          # í•œêµ­ì–´ ë„ì–´ì“°ê¸° êµì • í™œì„±í™”

teacher:
  backend: "ollama"
  model: "qwen3:8b"
  temperature: 0.3

questions:
  categories:
    policy_overview:
      - "ì´ ì •ì±…ì˜ ì£¼ìš” ëª©ì ì€ ë¬´ì—‡ì…ë‹ˆê¹Œ?"
      - "ì •ì±… ëŒ€ìƒìëŠ” ëˆ„êµ¬ì…ë‹ˆê¹Œ?"
      - "ì •ì±…ì˜ ì‹œí–‰ ê¸°ê°„ì€ ì–¸ì œì…ë‹ˆê¹Œ?"
    policy_details:
      - "ì§€ì› ë‚´ìš©ê³¼ ê·œëª¨ëŠ” ì–´ë–»ê²Œ ë©ë‹ˆê¹Œ?"
      - "ì‹ ì²­ ìê²© ìš”ê±´ì€ ë¬´ì—‡ì…ë‹ˆê¹Œ?"
      - "ì‹ ì²­ ì ˆì°¨ëŠ” ì–´ë–»ê²Œ ë©ë‹ˆê¹Œ?"

student:
  model: "google/gemma-3-1b-it"

export:
  ollama:
    model_name: "policy-assistant-ko"
    system_prompt: "ë‹¹ì‹ ì€ í•œêµ­ ì •ë¶€ ì •ì±… ì „ë¬¸ ìƒë‹´ ë„ìš°ë¯¸ì…ë‹ˆë‹¤."
```

**ì‹¤í–‰**:
```bash
# íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
slm-factory run --config policy-project/project.yaml

# ëª¨ë¸ ë°°í¬ ë° í…ŒìŠ¤íŠ¸
cd policy-project/output/merged_model
ollama create policy-assistant-ko -f Modelfile
ollama run policy-assistant-ko
```

---

### ì˜ˆì‹œ 2: ì˜ë¬¸ ê¸°ìˆ  ë¬¸ì„œ(PDF) â†’ ê¸°ìˆ  ë¬¸ì„œ ì „ë¬¸ ëª¨ë¸

ì†Œí”„íŠ¸ì›¨ì–´ API ë¬¸ì„œ(PDF)ë¥¼ í•™ìŠµí•˜ì—¬ ê°œë°œì ì§€ì› ëª¨ë¸ì„ ìƒì„±í•©ë‹ˆë‹¤.

**ì„¤ì • íŒŒì¼** (`tech-docs/project.yaml`):
```yaml
project:
  name: "api-assistant"
  language: "en"

paths:
  documents: "./documents"
  output: "./output"

parsing:
  formats: ["pdf"]
  pdf:
    extract_tables: true

teacher:
  backend: "ollama"
  model: "qwen3:8b"
  temperature: 0.2              # ê¸°ìˆ  ë¬¸ì„œëŠ” ë‚®ì€ temperature ê¶Œì¥

questions:
  categories:
    api_basics:
      - "What is the purpose of this API?"
      - "What are the authentication requirements?"
      - "What is the base URL for API requests?"
    api_usage:
      - "What are the available endpoints?"
      - "What parameters does this endpoint accept?"
      - "What is the expected response format?"
      - "What are common error codes and their meanings?"
    examples:
      - "Provide a code example for this functionality."
      - "What are best practices for using this API?"

validation:
  enabled: true
  groundedness:
    enabled: true               # ì˜ë¯¸ì  ê²€ì¦ í™œì„±í™”
    threshold: 0.3

student:
  model: "google/gemma-3-1b-it"

training:
  num_epochs: 15
  learning_rate: 1.5e-5

export:
  ollama:
    model_name: "api-assistant"
    system_prompt: "You are a helpful API documentation assistant."
```

**ì‹¤í–‰**:
```bash
# íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
slm-factory run --config tech-docs/project.yaml
```

---

### ì˜ˆì‹œ 3: ê¸°ì¡´ QA ë°ì´í„°ë¡œ í•™ìŠµë§Œ ì‹¤í–‰

ì´ë¯¸ ì¤€ë¹„ëœ QA ë°ì´í„°ì…‹ì´ ìˆëŠ” ê²½ìš°, íŒŒì‹±ê³¼ ìƒì„± ë‹¨ê³„ë¥¼ ê±´ë„ˆë›°ê³  í•™ìŠµë§Œ ì‹¤í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

**QA ë°ì´í„° í˜•ì‹** (`custom_qa.jsonl`):
```jsonl
{"messages": [{"role": "user", "content": "What is Python?"}, {"role": "assistant", "content": "Python is a high-level programming language..."}]}
{"messages": [{"role": "user", "content": "How do I install packages?"}, {"role": "assistant", "content": "Use pip install <package-name>..."}]}
```

**ì‹¤í–‰**:
```bash
slm-factory train --config project.yaml --data ./custom_qa.jsonl
```

ì´ ë°©ì‹ì€ ë‹¤ìŒê³¼ ê°™ì€ ê²½ìš°ì— ìœ ìš©í•©ë‹ˆë‹¤:
- ì™¸ë¶€ì—ì„œ ì¤€ë¹„í•œ QA ë°ì´í„°ì…‹ì„ ì‚¬ìš©í•˜ëŠ” ê²½ìš°
- ì—¬ëŸ¬ ë²ˆ í•™ìŠµ í•˜ì´í¼íŒŒë¼ë¯¸í„°ë¥¼ ì¡°ì •í•˜ë©° ì‹¤í—˜í•˜ëŠ” ê²½ìš°
- íŒŒì‹±ê³¼ ìƒì„± ë‹¨ê³„ê°€ ì´ë¯¸ ì™„ë£Œëœ ê²½ìš°

---

## 12. íŠ¸ëŸ¬ë¸”ìŠˆíŒ…

### 1. Ollama ì—°ê²° ì‹¤íŒ¨

**ì¦ìƒ**:
```
Error: Failed to connect to Ollama at http://localhost:11434
```

**í•´ê²° ë°©ë²•**:
- Ollama ì„œë²„ê°€ ì‹¤í–‰ ì¤‘ì¸ì§€ í™•ì¸í•˜ì‹­ì‹œì˜¤:
  ```bash
  ollama serve
  ```
- `project.yaml`ì˜ `teacher.api_base` ì„¤ì •ì´ ì˜¬ë°”ë¥¸ì§€ í™•ì¸í•˜ì‹­ì‹œì˜¤:
  ```yaml
  teacher:
    api_base: "http://localhost:11434"  # Ollama ê¸°ë³¸ í¬íŠ¸
  ```
- ë°©í™”ë²½ì´ë‚˜ ë„¤íŠ¸ì›Œí¬ ì„¤ì •ì´ 11434 í¬íŠ¸ë¥¼ ì°¨ë‹¨í•˜ì§€ ì•ŠëŠ”ì§€ í™•ì¸í•˜ì‹­ì‹œì˜¤

---

### 2. GPU ë©”ëª¨ë¦¬ ë¶€ì¡± (CUDA Out of Memory)

**ì¦ìƒ**:
```
RuntimeError: CUDA out of memory. Tried to allocate X.XX GiB
```

**í•´ê²° ë°©ë²•**:

**ë°©ë²• 1**: ì–‘ìí™” í™œì„±í™” (ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ 50% ê°ì†Œ)
```yaml
training:
  quantization:
    enabled: true
    bits: 4
```

**ë°©ë²• 2**: ë°°ì¹˜ í¬ê¸° ê°ì†Œ
```yaml
training:
  batch_size: 2                    # ê¸°ë³¸ê°’ 4ì—ì„œ ê°ì†Œ
  gradient_accumulation_steps: 8   # ì´ ë°°ì¹˜ í¬ê¸° ìœ ì§€
```

**ë°©ë²• 3**: ë” ì‘ì€ Student ëª¨ë¸ ì‚¬ìš©
```yaml
student:
  model: "TinyLlama/TinyLlama-1.1B-Chat-v1.0"  # 1B ëª¨ë¸
```

**ë°©ë²• 4**: CPU í•™ìŠµ (ëŠë¦¬ì§€ë§Œ ë©”ëª¨ë¦¬ ì œì•½ ì—†ìŒ)
```yaml
training:
  bf16: false                      # CPUëŠ” bf16 ë¯¸ì§€ì›
```

---

### 3. HWPX íŒŒì‹± ì‹¤íŒ¨

**ì¦ìƒ**:
```
Error: Failed to parse HWPX file - section0.xml not found
```

**í•´ê²° ë°©ë²•**:
- HWPX íŒŒì¼ì´ ì†ìƒë˜ì§€ ì•Šì•˜ëŠ”ì§€ í™•ì¸í•˜ì‹­ì‹œì˜¤ (í•œê¸€ì—ì„œ ì—´ì–´ë³´ê¸°)
- HWPX íŒŒì¼ì´ ì•”í˜¸í™”ë˜ì–´ ìˆì§€ ì•Šì€ì§€ í™•ì¸í•˜ì‹­ì‹œì˜¤
- íŒŒì¼ í™•ì¥ìê°€ `.hwpx`ì¸ì§€ í™•ì¸í•˜ì‹­ì‹œì˜¤ (`.hwp`ëŠ” ì§€ì›í•˜ì§€ ì•ŠìŒ)
- ìµœì‹  í•œê¸€ ë²„ì „ì—ì„œ HWPXë¡œ ë‹¤ì‹œ ì €ì¥í•´ë³´ì‹­ì‹œì˜¤

---

### 4. pykospacing ì„¤ì¹˜ ì˜¤ë¥˜

**ì¦ìƒ**:
```
ERROR: Could not install packages due to an OSError
```

**í•´ê²° ë°©ë²•**:

**ë°©ë²• 1**: Python ë²„ì „ í™•ì¸ (3.11 ì´ìƒ í•„ìš”)
```bash
python --version
```

**ë°©ë²• 2**: Gitì´ ì„¤ì¹˜ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸ (pykospacingì€ Git ì €ì¥ì†Œì—ì„œ ì„¤ì¹˜)
```bash
git --version
```

**ë°©ë²• 3**: ìˆ˜ë™ ì„¤ì¹˜ ì‹œë„
```bash
pip install git+https://github.com/haven-jeon/PyKoSpacing.git
```

**ë°©ë²• 4**: í•œêµ­ì–´ ë„ì–´ì“°ê¸° êµì • ë¹„í™œì„±í™”
```yaml
parsing:
  hwpx:
    apply_spacing: false
```

---

### 5. í•™ìŠµ ë°ì´í„° ë¶€ì¡± ê²½ê³ 

**ì¦ìƒ**:
```
Warning: Only 15 QA pairs generated. Recommend at least 100 for effective training.
```

**í•´ê²° ë°©ë²•**:

**ë°©ë²• 1**: ë” ë§ì€ ë¬¸ì„œ ì¶”ê°€
```bash
cp /path/to/more/documents/*.pdf ./documents/
```

**ë°©ë²• 2**: ì§ˆë¬¸ ì¹´í…Œê³ ë¦¬ í™•ì¥
```yaml
questions:
  categories:
    overview: [...]
    technical: [...]
    implementation: [...]
    additional:                    # ìƒˆ ì¹´í…Œê³ ë¦¬ ì¶”ê°€
      - "What are the benefits?"
      - "What are the limitations?"
```

**ë°©ë²• 3**: Teacher ëª¨ë¸ì˜ ì»¨í…ìŠ¤íŠ¸ í¬ê¸° ì¦ê°€
```yaml
teacher:
  max_context_chars: 20000         # ê¸°ë³¸ê°’ 12000ì—ì„œ ì¦ê°€
```

---

### 6. ë¹ˆ QA ì‘ë‹µ ìƒì„±

**ì¦ìƒ**:
ëŒ€ë¶€ë¶„ì˜ QA ìŒì´ "The document does not contain this information."ìœ¼ë¡œ ìƒì„±ë¨

**í•´ê²° ë°©ë²•**:

**ë°©ë²• 1**: Teacher ëª¨ë¸ íƒ€ì„ì•„ì›ƒ ì¦ê°€
```yaml
teacher:
  timeout: 300                     # ê¸°ë³¸ê°’ 180ì´ˆì—ì„œ ì¦ê°€
```

**ë°©ë²• 2**: ë‹¤ë¥¸ Teacher ëª¨ë¸ ì‹œë„
```yaml
teacher:
  model: "llama3.1:8b"             # ë˜ëŠ” "mistral:7b"
```

**ë°©ë²• 3**: ì§ˆë¬¸ì„ ë¬¸ì„œ ë‚´ìš©ì— ë§ê²Œ ì¡°ì •
- ë¬¸ì„œë¥¼ ë¨¼ì € ì½ê³  ì‹¤ì œë¡œ ë‹µë³€ ê°€ëŠ¥í•œ ì§ˆë¬¸ìœ¼ë¡œ ìˆ˜ì •í•˜ì‹­ì‹œì˜¤
- ë„ˆë¬´ ì¼ë°˜ì ì´ê±°ë‚˜ ì¶”ìƒì ì¸ ì§ˆë¬¸ì€ í”¼í•˜ì‹­ì‹œì˜¤

**ë°©ë²• 4**: System prompt ì¡°ì •
```yaml
questions:
  system_prompt: >
    Answer the question based on the document. 
    Provide detailed answers with specific information.
    If the exact answer is not in the document, provide related information.
```

---

## 13. í”„ë¡œì íŠ¸ êµ¬ì¡°

```
slm-factory/
â”œâ”€â”€ src/
â”‚   â””â”€â”€ slm_factory/
â”‚       â”œâ”€â”€ __init__.py              # íŒ¨í‚¤ì§€ ì´ˆê¸°í™” ë° ë²„ì „ ì •ë³´
â”‚       â”œâ”€â”€ __main__.py              # python -m slm_factory ì§„ì…ì 
â”‚       â”œâ”€â”€ cli.py                   # CLI ì§„ì…ì  ë° ëª…ë ¹ì–´ ì •ì˜
â”‚       â”œâ”€â”€ config.py                # Pydantic ê¸°ë°˜ ì„¤ì • ìŠ¤í‚¤ë§ˆ
â”‚       â”œâ”€â”€ models.py                # ê³µìœ  ë°ì´í„° ëª¨ë¸ (QAPair, ParsedDocument)
â”‚       â”œâ”€â”€ pipeline.py              # íŒŒì´í”„ë¼ì¸ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„°
â”‚       â”œâ”€â”€ scorer.py                # QA í’ˆì§ˆ ì ìˆ˜ í‰ê°€ (Teacher LLM)
â”‚       â”œâ”€â”€ augmenter.py             # QA ë°ì´í„° ì¦ê°• (ì§ˆë¬¸ íŒ¨ëŸ¬í”„ë ˆì´ì¦ˆ)
â”‚       â”œâ”€â”€ analyzer.py              # í•™ìŠµ ë°ì´í„° í†µê³„ ë¶„ì„
â”‚       â”œâ”€â”€ evaluator.py             # ëª¨ë¸ ìë™ í‰ê°€ (BLEU/ROUGE)
â”‚       â”œâ”€â”€ comparator.py            # ëª¨ë¸ ë¹„êµ (Before/After)
â”‚       â”œâ”€â”€ incremental.py           # ì¦ë¶„ í•™ìŠµ ì¶”ì 
â”‚       â”œâ”€â”€ converter.py             # ì±„íŒ… í…œí”Œë¦¿ ë³€í™˜ê¸°
â”‚       â”œâ”€â”€ utils.py                 # ìœ í‹¸ë¦¬í‹° ë° ë¡œê¹… ì„¤ì •
â”‚       â”œâ”€â”€ tui/
â”‚       â”‚   â”œâ”€â”€ __init__.py          # TUI íŒ¨í‚¤ì§€
â”‚       â”‚   â”œâ”€â”€ widgets.py           # TUI ìœ„ì ¯ (QACard, StatusBar)
â”‚       â”‚   â”œâ”€â”€ reviewer.py          # QA ìˆ˜ë™ ë¦¬ë·° TUI
â”‚       â”‚   â””â”€â”€ dashboard.py         # íŒŒì´í”„ë¼ì¸ ëŒ€ì‹œë³´ë“œ TUI
â”‚       â”œâ”€â”€ parsers/
â”‚       â”‚   â”œâ”€â”€ __init__.py          # íŒŒì„œ ë ˆì§€ìŠ¤íŠ¸ë¦¬
â”‚       â”‚   â”œâ”€â”€ base.py              # íŒŒì„œ ê¸°ë³¸ í´ë˜ìŠ¤
â”‚       â”‚   â”œâ”€â”€ pdf.py               # PDF íŒŒì„œ (PyMuPDF)
â”‚       â”‚   â”œâ”€â”€ hwpx.py              # HWPX íŒŒì„œ (í•œê¸€ ë¬¸ì„œ)
â”‚       â”‚   â”œâ”€â”€ html.py              # HTML íŒŒì„œ (BeautifulSoup)
â”‚       â”‚   â”œâ”€â”€ text.py              # TXT/MD íŒŒì„œ
â”‚       â”‚   â””â”€â”€ docx.py              # DOCX íŒŒì„œ (python-docx)
â”‚       â”œâ”€â”€ teacher/
â”‚       â”‚   â”œâ”€â”€ __init__.py          # Teacher LLM íŒ©í† ë¦¬
â”‚       â”‚   â”œâ”€â”€ base.py              # Teacher ê¸°ë³¸ í´ë˜ìŠ¤
â”‚       â”‚   â”œâ”€â”€ ollama.py            # Ollama ë°±ì—”ë“œ
â”‚       â”‚   â”œâ”€â”€ openai_compat.py     # OpenAI í˜¸í™˜ API ë°±ì—”ë“œ
â”‚       â”‚   â”œâ”€â”€ qa_generator.py      # QA ìŒ ìƒì„± ë¡œì§
â”‚       â”‚   â””â”€â”€ dialogue_generator.py  # ë©€í‹°í„´ ëŒ€í™” ìƒì„±
â”‚       â”œâ”€â”€ validator/
â”‚       â”‚   â”œâ”€â”€ __init__.py          # ê²€ì¦ ëª¨ë“ˆ ì´ˆê¸°í™”
â”‚       â”‚   â”œâ”€â”€ rules.py             # ê·œì¹™ ê¸°ë°˜ ê²€ì¦ (ê¸¸ì´, íŒ¨í„´ ë“±)
â”‚       â”‚   â””â”€â”€ similarity.py        # ì„ë² ë”© ê¸°ë°˜ groundedness ì²´í¬
â”‚       â”œâ”€â”€ trainer/
â”‚       â”‚   â”œâ”€â”€ __init__.py          # í•™ìŠµ ëª¨ë“ˆ ì´ˆê¸°í™”
â”‚       â”‚   â””â”€â”€ lora_trainer.py      # LoRA íŒŒì¸íŠœë‹ (SFTTrainer, DataLoader í¬í•¨)
â”‚       â””â”€â”€ exporter/
â”‚           â”œâ”€â”€ __init__.py          # ë‚´ë³´ë‚´ê¸° ëª¨ë“ˆ ì´ˆê¸°í™”
â”‚           â”œâ”€â”€ hf_export.py         # HuggingFace ëª¨ë¸ ë³‘í•©
â”‚           â”œâ”€â”€ ollama_export.py     # Ollama Modelfile ìƒì„±
â”‚           â””â”€â”€ gguf_export.py       # GGUF ì–‘ìí™” ë³€í™˜
â”œâ”€â”€ templates/
â”‚   â””â”€â”€ project.yaml                 # ê¸°ë³¸ í”„ë¡œì íŠ¸ í…œí”Œë¦¿
â”œâ”€â”€ tests/
â”‚   â””â”€â”€ __init__.py                  # í…ŒìŠ¤íŠ¸ íŒ¨í‚¤ì§€
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ architecture.md              # ì•„í‚¤í…ì²˜ ê°€ì´ë“œ
â”‚   â”œâ”€â”€ configuration.md             # ì„¤ì • ë ˆí¼ëŸ°ìŠ¤
â”‚   â””â”€â”€ modules.md                   # ëª¨ë“ˆë³„ ìƒì„¸ ë¬¸ì„œ
â”œâ”€â”€ pyproject.toml                   # í”„ë¡œì íŠ¸ ë©”íƒ€ë°ì´í„° ë° ì˜ì¡´ì„±
â””â”€â”€ README.md                        # ì´ ë¬¸ì„œ
```

---

## 14. ê´€ë ¨ ë¬¸ì„œ

í”„ë¡œì íŠ¸ì— ëŒ€í•œ ë” ìì„¸í•œ ì •ë³´ëŠ” ë‹¤ìŒ ë¬¸ì„œë¥¼ ì°¸ì¡°í•˜ì‹­ì‹œì˜¤:

- **[ì•„í‚¤í…ì²˜ ê°€ì´ë“œ](docs/architecture.md)**: slm-factoryì˜ ë‚´ë¶€ êµ¬ì¡°ì™€ ì„¤ê³„ ì›ì¹™ì„ ì„¤ëª…í•©ë‹ˆë‹¤
- **[ì„¤ì • ë ˆí¼ëŸ°ìŠ¤](docs/configuration.md)**: `project.yaml`ì˜ ëª¨ë“  ì„¤ì • ì˜µì…˜ì— ëŒ€í•œ ìƒì„¸ ì„¤ëª…ì„ ì œê³µí•©ë‹ˆë‹¤
- **[ëª¨ë“ˆë³„ ìƒì„¸ ë¬¸ì„œ](docs/modules.md)**: ê° ëª¨ë“ˆ(íŒŒì„œ, Teacher, ê²€ì¦ê¸° ë“±)ì˜ APIì™€ í™•ì¥ ë°©ë²•ì„ ì•ˆë‚´í•©ë‹ˆë‹¤
- **[ìì£¼ ë¬»ëŠ” ì§ˆë¬¸ (FAQ)](docs/faq.md)**: Ollama ì—°ê²°, GPU ë©”ëª¨ë¦¬, QA í’ˆì§ˆ ë“± ìì£¼ ë°œìƒí•˜ëŠ” ë¬¸ì œì˜ í•´ê²° ë°©ë²•ì„ ì•ˆë‚´í•©ë‹ˆë‹¤

---

## 15. ë¼ì´ì„ ìŠ¤

ì´ í”„ë¡œì íŠ¸ì˜ ë¼ì´ì„ ìŠ¤ëŠ” ì¶”í›„ ê²°ì •ë©ë‹ˆë‹¤.

---

**slm-factory**ë¡œ ë„ë©”ì¸ íŠ¹í™” ì–¸ì–´ëª¨ë¸ì„ ì‰½ê³  ë¹ ë¥´ê²Œ êµ¬ì¶•í•˜ì‹­ì‹œì˜¤!
